{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be5c7d9-1cac-4711-a367-c4308a283c25",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "Transformers are a type of deep learning model introduced by Hugging Face, a company known for its work in natural language processing (NLP). They are designed to handle sequential data, such as text, and have been highly successful in various NLP tasks like text classification, question answering, and language translation.\n",
    "\n",
    "https://github.com/huggingface/notebooks/tree/main/course/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de67a79b-ee93-4efc-801b-255297229a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.43.3\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: C:\\Users\\Catello\\anaconda3\\Lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982044dc-a981-4d19-ba2f-ba65ba71acc8",
   "metadata": {},
   "source": [
    "### BERT\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based model developed by Google. It is designed to understand the context of words in a sentence by processing text bidirectionally, meaning it considers both the left and right context of a word. BERT\n",
    "\n",
    "#### Sentiment analysis\n",
    "This is a pipeline provided by the Hugging Face Transformers library. It allows you to easily perform sentiment analysis on text. The pipeline abstracts away the complexities of loading models and tokenizers, making it straightforward to use pre-trained models for specific tasks like sentiment analysis.\n",
    "\n",
    "#### DistilBERT\n",
    "is a smaller, faster, cheaper, and lighter version of the BERT model. It is designed to retain most of the language understanding capabilities of BERT while being more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646cb957-0f84-46e7-b92a-6f1eb5fabe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999886155128479}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I am having a wonderful day today!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27844f-2eca-407f-a21f-9b55783e647f",
   "metadata": {},
   "source": [
    "### Classification\n",
    "refers to the process of categorizing or labeling data into predefined groups or classes based on certain features or characteristics. In the context of natural language processing (NLP), classification can involve tasks such as sentiment analysis, where text is classified into categories like positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25465bb-5ecd-480e-8b12-cfd43685625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db294ca-bf59-4220-8606-11f88e8904e5",
   "metadata": {},
   "source": [
    "### Zero-shot classification\n",
    "Zero-shot classification is a type of classification task where the model is asked to classify text into categories that it has not been explicitly trained on. This is particularly useful when you have a pre-trained model and you want to use it for new, unseen categories without having to retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b226b51a-bbd8-4a8b-8332-b618c4369f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"Exploring the wonders of space travel is an exciting adventure\",\n",
    "    candidate_labels=[\"science\", \"travel\", \"entertainment\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4d240-5d39-4d6e-a8d6-091817dae698",
   "metadata": {},
   "source": [
    "### Text generation\n",
    "Text generation is a natural language processing (NLP) task where a model generates coherent and contextually relevant text based on an initial input or prompt. This can be used for a variety of applications, such as writing assistance, story generation, chatbots, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be5a63-cfd0-4a64-bebd-646db76ca9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"Today, we are going to \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9fd2b4-7c87-4371-b249-4a0b5e472bf3",
   "metadata": {},
   "source": [
    "### GPT-2 model\n",
    "GPT-2 (Generative Pre-trained Transformer 2) is a large-scale language model developed by OpenAI. It is designed to generate human-like text based on an input prompt.\n",
    "\n",
    "#### distilgpt2\n",
    "This parameter specifies the pre-trained model to use for text generation. In this case, distilgpt2 is a distilled version of the GPT-2 model. Distillation is a technique used to create smaller, faster models that retain most of the performance of the original model.\n",
    "\n",
    "### Parameter Engineering\n",
    "Parameter engineering involves fine-tuning the parameters of the text generation model to control the output\n",
    "- **max_lengt** This parameter sets the maximum length of the generated text in terms of tokens. Tokens are the basic units of text that the model processes, which can be words or subwords\n",
    "- **num_return_sequence** This parameter specifies the number of different sequences (or continuations) that the model should generate from the input prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb1564-3c66-45b6-b3f8-eb3f6660f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"Let's discover the secrets of\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8490b09a-0e7d-40d3-9b11-930bafa6d9c9",
   "metadata": {},
   "source": [
    "### Words predictions\n",
    "\n",
    "The model generates predictions for the masked token based on the context of the surrounding words.\n",
    "\n",
    "#### fill-mask\n",
    "task is a common NLP task where the model predicts the most likely word(s) to fill in a masked token in a sentence. This is particularly useful for tasks like language modeling, text completion, and understanding context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bededf3f-7aa4-416c-b30b-8ef81a786eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"The secret to success is <mask> and hard work.\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec768e03-90eb-4b83-b31f-dbea93ceb74d",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "NER is a common NLP task where the model identifies and classifies named entities in a text, such as names of people, organizations, locations, dates, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91848ee3-0604-4f75-8124-cf678f32b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"Carl lives in Paris and work at Amazon.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454ec56-47a5-4f92-b819-3b5a7f6f747c",
   "metadata": {},
   "source": [
    "### Summarization\n",
    "Summarization is a natural language processing (NLP) task that involves generating a concise and coherent summary of a longer text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974ed97-7db5-460f-a637-8430a7d3ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    The field of artificial intelligence has seen remarkable advancements in recent years. Machine learning, a subset of AI, has become increasingly important in various industries, from healthcare to finance. Deep learning, a more specialized form of machine learning, has enabled significant breakthroughs in areas such as image recognition, natural language processing, and autonomous systems.\n",
    "\n",
    "    Companies and researchers around the world are investing heavily in AI research and development. This has led to the creation of sophisticated algorithms and models that can perform complex tasks with high accuracy. However, there are also ethical considerations and challenges that need to be addressed, such as data privacy, bias, and the potential impact on employment.\n",
    "\n",
    "    As AI continues to evolve, it is crucial to ensure that its benefits are distributed equitably and that its potential risks are managed responsibly. This requires collaboration between policymakers, industry leaders, and the public to develop robust frameworks for the ethical use of AI.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb6dbe-b19b-4fb2-a3b0-03047cf33de5",
   "metadata": {},
   "source": [
    "### SentencePiece\n",
    "SentencePiece is a natural language processing (NLP) library that provides tools for sentence segmentation and phrase compression. It is often used for text preprocessing in natural language processing models, such as transformer models\n",
    "\n",
    "#### Helsinki-NLP/opus-mt-fr-en\n",
    "Ce modèle est un modèle de machine learning entraîné pour effectuer la traduction automatique du français vers l'anglais en utilisant la bibliothèque de transformers de Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15186e0-9722-4922-a99c-8f5b9f13e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ce947-a810-469f-857b-87c02400b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "translator(\"Elle adore lire des livres.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15694a-2be2-4ed3-97f6-9e8db9da82e7",
   "metadata": {},
   "source": [
    "### Bias and limitations (BERT)\n",
    "pre-trained language models like BERT, and to take steps to mitigate them as much as possible. This can include using techniques like debiasing, fine-tuning the model on specific tasks or domains, and carefully evaluating the outputs of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4238b-b027-4206-a106-786dea19509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "result = unmasker(\"He is a [MASK] of many talents.\")\n",
    "print([r[\"token_str\"] for r in result])\n",
    "\n",
    "result = unmasker(\"She is a [MASK] of many talents.\")\n",
    "print([r[\"token_str\"] for r in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d03b0c-f493-4726-b12f-0f9f3a098676",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "PyTorch is an open-source framework for machine learning and artificial intelligence, developed by Facebook's AI Research lab. It is designed to be flexible and easy to use, making it popular among researchers and developers working on advanced AI projects.\n",
    "\n",
    "### Behind the pipeline (PyTorch)\n",
    "\n",
    "**A tensor** is a multi-dimensional data object used in the context of the PyTorch library, which is often used for natural language modeling and machine learning. Tensors are used to store and manipulate numerical data, such as matrices and arrays.\r\n",
    "\r\n",
    "In the context of the transformer library, tensors are used to store the inputs and outputs of transformer models.r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b29130-9aef-468b-8745-970faed0d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I'm so excited to start this course!\",\n",
    "        \"I can't stand this anymore.\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05fa38-2e97-46e2-99d5-9db1a6a474b2",
   "metadata": {},
   "source": [
    "This code takes two sentences as input and converts them into token identifiers and attention masks, which can be used to feed a transformer model for sentiment classification.\n",
    "\n",
    "- **input_ids** This is a tensor that contains the token identifiers for each input sentence.\n",
    "- **attention_mask** This is a binary tensor that indicates to transformer models which tokens should be considered when calculating attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cb540-3275-42f4-a545-b7edff7b55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "     \n",
    "\n",
    "raw_inputs = [\n",
    "        \"I'm so excited to start this course!\",\n",
    "        \"I can't stand this anymore.\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86b69d-aa9f-461c-abeb-2bcdc4ae526c",
   "metadata": {},
   "source": [
    "### The DistilBERT Model\r\n",
    "This code loads a fine-tuned DistilBERT model for English sentiment classification from a given checkpoint, and then uses this model to process the previously generated tokenized inputs.\n",
    "\n",
    "#### AutoModel\r\n",
    "\r\n",
    "The model output is a tensor of dimensions 2 x 16 x 768, where each value is a contextual representation for a specific token in a specific input example. These contextual representations can be used as inputs for further processing layers, or to make decisions based on the content of the input examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafcd7a-4a97-4916-8259-ee7144665b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "     \n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdb7d14-91db-4bce-a9c6-496fbfc9abe7",
   "metadata": {},
   "source": [
    "#### AutoModelForSequenceClassification\n",
    "\n",
    "Ce code charge un modèle de classification de séquence finement ajusté à partir d'un point de contrôle DistilBERT pour la tâche SST-2 (Sentiment Analysis on Stanford Sentiment Treebank), puis utilise ce modèle pour traiter les entrées tokenisées précédemment générées.\n",
    "\n",
    "The model output is a tensor  containing logits for 2 input examples, each with 2 possible output classes (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f36567-fa8e-432a-a574-b3916bb20b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0d426-3bd2-407f-b4f6-20cdc69b4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs.logits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a2de9-7b98-4640-871f-9cdb5da33e82",
   "metadata": {},
   "source": [
    "#### Classification scores\n",
    "Classification scores can be used to make decisions based on the content of the input examples. For example, the model can be used to predict the most probable output class for each input example by selecting the class with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfd05e-7574-4957-9eae-c6c294004f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a733b2-d484-4d62-8f15-ffb21b9ed7fc",
   "metadata": {},
   "source": [
    "#### Normalized classification scores\n",
    "Normalized classification scores can be used to make decisions based on the probability of the output classes for each input example. For example, the model can be used to predict the most probable output class for each input example by selecting the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d5c5c-2ae1-4a50-ad24-5b356d12636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ab5e5-1d47-4392-8650-d1348df5d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805edb0a-0e3d-4f57-9110-366ab208e653",
   "metadata": {},
   "source": [
    "## Models (PyTorch)\n",
    "This code uses a language model called BERT to turn phrases into numbers (called \"embeddings\") that can be used to train another machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e642834-18e0-46ed-a75c-cc6da2c87d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Building the config\n",
    "config = BertConfig()\n",
    "\n",
    "# Building the model from the config\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657cd19d-7bdd-420f-b8a2-a509e5c48dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae70d9-8940-47fe-85b9-7df8f97cfac0",
   "metadata": {},
   "source": [
    "### bert-base-cased\n",
    "So, \"bert-base-cased\" is a pre-trained BERT model with 12 layers, a hidden size of 768, 12 self-attention heads, and case sensitivity. It has been pre-trained on the English Wikipedia and BookCorpus datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de096734-9419-480f-ad11-0278d3c8f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5c6fc-1a74-4df6-b145-d6bbfa4118ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"C:/Users/Catello/Desktop/Protfolio/prompt_engineering/models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ae4761-74ef-45ba-b283-6bb45f2897a0",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "The correspondence between words and numbers is simply a way for the model to represent words numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d871376e-b85e-45f6-b592-e28aed16a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02852f19-68e8-4369-a065-5c84b27baf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = [\n",
    "    [101, 7592, 999, 102],\n",
    "    [101, 4658, 1012, 102],\n",
    "    [101, 3835, 999, 102],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4350ef1-5e17-40fb-99cc-35ab70530ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_inputs = torch.tensor(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62749e-6dee-4155-833f-5f05df577289",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d257d9-6378-4dfe-8db9-d9767e0903be",
   "metadata": {},
   "source": [
    "## Tokenizers (PyTorch)\n",
    "\n",
    "A tokenizer is a tool that allows converting text into a sequence of tokens (or words) that can be used as inputs for a language processing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f61384-10d5-4d52-9ce1-cf2090483b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jack', 'Sparrow', 'was', 'pirate']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = \"Jack Sparrow was pirate\".split()\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37ab069f-c44e-4bdd-8f4f-e403e1636646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a3b6728-8f61-4923-8009-c0ad585c6060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1422, 4113, 1110, 170, 1363, 9834, 1200, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"My mom is a good cooker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9c65f51-0e2f-4c89-974b-f361ff0bf6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:/Users/Catello/Desktop/Protfolio/prompt_engineering/models\\\\tokenizer_config.json',\n",
       " 'C:/Users/Catello/Desktop/Protfolio/prompt_engineering/models\\\\special_tokens_map.json',\n",
       " 'C:/Users/Catello/Desktop/Protfolio/prompt_engineering/models\\\\vocab.txt',\n",
       " 'C:/Users/Catello/Desktop/Protfolio/prompt_engineering/models\\\\added_tokens.json',\n",
       " 'C:/Users/Catello/Desktop/Protfolio/prompt_engineering/models\\\\tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"C:/Users/Catello/Desktop/Protfolio/prompt_engineering/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99aa1682-c0cf-43c9-be7e-f1793b87d008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'mom', 'is', 'a', 'good', 'cook', '##er']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"My mom is a good cooker\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "\n",
    "print(tokens)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bd50e94-a98a-4c20-936a-49d8cb65fed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1422, 4113, 1110, 170, 1363, 9834, 1200]\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1654d43-2440-4b96-81ce-325025df35d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My mom is a good cooker\n"
     ]
    }
   ],
   "source": [
    "decoded_string = tokenizer.decode([1422, 4113, 1110, 170, 1363, 9834, 1200])\n",
    "print(decoded_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
